{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a16156",
   "metadata": {},
   "source": [
    "# Build Window-Level Features\n",
    "\n",
    "Aggregate frame-level facial features (EAR, MAR, etc.) into window-level samples and add temporal features (blink/yawn ratios, EAR dynamics) that can be used by traditional machine learning models for drowsiness recognition.\n",
    "\n",
    "The label definition follows the UTA-RLDD (https://sites.google.com/view/utarldd/home) dataset description:\n",
    "- Each original video belongs to one of three classes:  \n",
    "  - **alert** (labeled as `0`)  \n",
    "  - **low vigilant** (labeled as `5`)  \n",
    "  - **drowsy** (labeled as `10`)  \n",
    "- In this project, we **only use the alert (`0`) and drowsy (`10`) classes**, and ignore the low vigilant (`5`) class.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Inputs\n",
    "\n",
    "- A CSV file with **frame-level features**, produced by `extract_frame_features.ipynb`:\n",
    "  - `exported_data/features_frame_level.csv`\n",
    "\n",
    "## 2. Outputs\n",
    "\n",
    "---\n",
    "\n",
    "- A CSV file with **window-level features**, saved to:\n",
    "  - `exported_data/features_window_level.csv`\n",
    "\n",
    "Each row in the window-level CSV corresponds to one **time window** within a given video, with the following columns:\n",
    "\n",
    "- `subject_id`: subject/folder identifier\n",
    "- `video_id`: video identifier\n",
    "- `window_id`: integer window index within the video\n",
    "- `ear_mean_mean`: mean EAR over all frames in the window\n",
    "- `ear_mean_std`: standard deviation of EAR in the window\n",
    "- `mar_mean`: mean MAR over all frames in the window\n",
    "- `mar_std`: standard deviation of MAR in the window\n",
    "- `blink_ratio`: fraction of frames in the window where `EAR < BLINK_EAR_THRESH` (proxy for eye closure -> blinking)\n",
    "- `yawn_ratio`: fraction of frames in the window where `MAR > YAWN_MAR_THRESH` (proxy for mouth opening -> yawning)\n",
    "- `ear_diff_mean`: mean absolute frame-to-frame change in EAR within the window (captures dynamics of eye opening/closing)\n",
    "- `num_frames`: number of frames contributing to this window\n",
    "- `label`: **window-level drowsiness label**\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Main objectives of this notebook\n",
    "\n",
    "1. Load the frame-level feature table from `exported_data/features_frame_level.csv` and sort frames by `subject_id`, `video_id`, and `frame_idx`.\n",
    "\n",
    "2. For each `(subject_id, video_id)` sequence:\n",
    "   - Assign a `frame_order` index within the video.\n",
    "   - Group frames into fixed-length time windows using a configurable `WINDOW_SIZE`, and assign a `window_id` to each frame.\n",
    "\n",
    "3. For each window (unique combination of `subject_id`, `video_id`, `window_id`):\n",
    "   - Aggregate frame-level EAR/MAR into summary statistics:\n",
    "     - `ear_mean_mean`, `ear_mean_std`\n",
    "     - `mar_mean`, `mar_std`\n",
    "   - Compute temporal features:\n",
    "     - `blink_ratio` based on `EAR < BLINK_EAR_THRESH`\n",
    "     - `yawn_ratio` based on `MAR > YAWN_MAR_THRESH`\n",
    "     - `ear_diff_mean` as the mean absolute difference of EAR between consecutive frames\n",
    "   - Count `num_frames` in the window.\n",
    "   - Assign a **window-level label**\n",
    "     - `video_id` starting with `\"0\"` → label `0` (alert)\n",
    "     - `video_id` starting with `\"10\"` → label `10` (drowsy)\n",
    "\n",
    "5. Create the `exported_data/` directory if it does not exist and save the final window-level feature table as `features_window_level.csv`, which will be used as input for traditional machine learning models for drowsiness recognition.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbfcfe",
   "metadata": {},
   "source": [
    "## Codes\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5881283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d180a6e",
   "metadata": {},
   "source": [
    "### 2. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9eadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many frames per time window\n",
    "WINDOW_SIZE = 60\n",
    "# STRIDE = 60 -> non-overlapping, stride == window_size\n",
    "# FPS, which is read from video metadata, ≈ 30\n",
    "# window_len_sec = WINDOW_SIZE / FPS = 2s\n",
    "\n",
    "# Thresholds for blink -> yawn detection \n",
    "BLINK_EAR_THRESH = 0.21   # EAR < this -> eye considered \"closed\"\n",
    "YAWN_MAR_THRESH  = 0.60   # MAR > this -> mouth considered \"open / yawn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d77c0",
   "metadata": {},
   "source": [
    "### 4. Load frame-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c71e648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frame-level features from: exported_data\\features_frame_level.csv\n"
     ]
    }
   ],
   "source": [
    "path = r\"exported_data\\features_frame_level.csv\"\n",
    "print(\"Loading frame-level features from:\", path)\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Basic sanity check\n",
    "expected_cols = {\"subject_id\", \"video_id\", \"frame_idx\", \"ear_mean\", \"mar\"}\n",
    "missing = expected_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns in frame-level CSV: {missing}\")\n",
    "\n",
    "# Ensure proper sorting by video & time\n",
    "df = df.sort_values([\"subject_id\", \"video_id\", \"frame_idx\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47703f",
   "metadata": {},
   "source": [
    "### 5. Create frame_order and window_id within each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b55238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_order\n",
    "df[\"frame_order\"] = df.groupby([\"subject_id\", \"video_id\"]).cumcount()\n",
    "\n",
    "# window_id\n",
    "df[\"window_id\"] = (df[\"frame_order\"] // WINDOW_SIZE).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ac3bc",
   "metadata": {},
   "source": [
    "### 6. Define aggregation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6460e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_window(group: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Aggregate certain frames in one window into a single feature vector.\n",
    "    `group` is a subset of df for one (subject_id, video_id, window_id).\n",
    "    \"\"\"\n",
    "    g = group.sort_values(\"frame_idx\")\n",
    "\n",
    "    ear = g[\"ear_mean\"].values\n",
    "    mar = g[\"mar\"].values\n",
    "\n",
    "    # Basic statistics\n",
    "    ear_mean = ear.mean()\n",
    "    ear_std  = ear.std()\n",
    "    mar_mean = mar.mean()\n",
    "    mar_std  = mar.std()\n",
    "\n",
    "    # blink_ratio: fraction of frames where EAR < threshold\n",
    "    blink_ratio = (ear < BLINK_EAR_THRESH).mean()\n",
    "\n",
    "    # yawn_ratio: fraction of frames where MAR > threshold\n",
    "    yawn_ratio = (mar > YAWN_MAR_THRESH).mean()\n",
    "\n",
    "    # ear_diff_mean: mean |EAR_t - EAR_{t-1}|\n",
    "    if len(ear) > 1:\n",
    "        ear_diff_mean = np.abs(np.diff(ear)).mean()\n",
    "    else:\n",
    "        ear_diff_mean = 0.0\n",
    "\n",
    "    # label: majority vote within the window\n",
    "    vid = str(g[\"video_id\"].iloc[0])\n",
    "    if vid.startswith(\"10\"):\n",
    "        label = \"drowsy\" # 10\n",
    "    elif vid.startswith(\"0\"):\n",
    "        label = \"alert\" # 0\n",
    "    else:\n",
    "        label = None\n",
    "\n",
    "    return pd.Series({\n",
    "        \"ear_mean_mean\": ear_mean,\n",
    "        \"ear_mean_std\": ear_std,\n",
    "        \"mar_mean\": mar_mean,\n",
    "        \"mar_std\": mar_std,\n",
    "        \"blink_ratio\": blink_ratio,\n",
    "        \"yawn_ratio\": yawn_ratio,\n",
    "        \"ear_diff_mean\": ear_diff_mean,\n",
    "        \"num_frames\": len(g),\n",
    "        \"label\": label,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e1036",
   "metadata": {},
   "source": [
    "### 7. Group by (`subject_id`, `video_id`, `window_id`) and aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f99a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating windows with groupby on: ['subject_id', 'video_id', 'window_id']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\temp11\\ipykernel_9392\\2105513857.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(agg_window)\n"
     ]
    }
   ],
   "source": [
    "group_cols = [\"subject_id\", \"video_id\", \"window_id\"]\n",
    "print(\"Aggregating windows with groupby on:\", group_cols)\n",
    "\n",
    "window_df = (\n",
    "    df\n",
    "    .groupby(group_cols, as_index=False)\n",
    "    .apply(agg_window)\n",
    "    .reset_index()  \n",
    ")\n",
    "\n",
    "for col in [\"level_0\", \"index\"]:\n",
    "    if col in window_df.columns:\n",
    "        window_df = window_df.drop(columns=[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843e91c",
   "metadata": {},
   "source": [
    "### 8. Save as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6853fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved window-level dataset to: exported_data\\features_window_level.csv\n",
      "Num windows: 17149\n",
      "   subject_id     video_id  window_id  ear_mean_mean  ear_mean_std  mar_mean  \\\n",
      "0           1  0_landmarks          0       0.283420      0.012871  0.133524   \n",
      "1           1  0_landmarks          1       0.297406      0.016750  0.134261   \n",
      "2           1  0_landmarks          2       0.287027      0.006120  0.134697   \n",
      "3           1  0_landmarks          3       0.290294      0.008107  0.133690   \n",
      "4           1  0_landmarks          4       0.291793      0.012964  0.134424   \n",
      "\n",
      "    mar_std  blink_ratio  yawn_ratio  ear_diff_mean  num_frames  label  \n",
      "0  0.003331          0.0         0.0       0.004260          60  alert  \n",
      "1  0.001269          0.0         0.0       0.005684          60  alert  \n",
      "2  0.001130          0.0         0.0       0.001528          60  alert  \n",
      "3  0.001217          0.0         0.0       0.002574          60  alert  \n",
      "4  0.000981          0.0         0.0       0.003801          60  alert  \n"
     ]
    }
   ],
   "source": [
    "out_path = r\"exported_data\\features_window_level.csv\"\n",
    "window_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved window-level dataset to:\", out_path)\n",
    "print(\"Num windows:\", len(window_df))\n",
    "print(window_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
